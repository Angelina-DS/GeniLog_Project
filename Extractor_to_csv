import requests
from bs4 import BeautifulSoup
import pandas as pd

link = 'https://en.wikipedia.org/wiki/Comparison_of_digital_SLRs'
linkBis = 'https://en.wikipedia.org/wiki/List_of_most_visited_websites' #Work but with 0 instead of 1
response = requests.get(link) #request which gets the url's encoded content
soup = BeautifulSoup(response.text,'html.parser') #reponse.text : url's decoded content
#print(soup.prettify()) 

#To save the html code of the Wikipedia page
#fichier = open("temp.txt", "a")
#fichier.write(soup.prettify())
#fichier.close()

def wikiTable_to_csv(url = str):
    tableName  = url.split("/")[-1]
    tables = pd.read_html(url, header=0) #reads html tables into a list of dataframe objects
    #print(tables)

    #If you want to test the code on linkBis, change the following "1"s by a "0"
    if not tables[1].empty:
        dataframeName = tableName + " table.csv"
        tables[1].to_csv(dataframeName, sep=',') 

result = wikiTable_to_csv(link)
print(result)
